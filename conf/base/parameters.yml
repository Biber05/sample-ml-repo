
### TRAINING

# Number of training epochs
epochs: 2
experiment_path: &experiment_path experiment_outputs/$RUN_ID-id_$SHORT_ID
project_package_name: &project_package_name mltemplate

# Callbacks used for training
# $RUN_ID is replaced with a timestring
# $SHORT_ID is a alphanumeric hash value of the $RUN_ID (easier to remember and search for)
callbacks:
  # Stores the model after each epoch
  - type: ccmlutils.callbacks.callback_factories.model_callback_factory
    params:
      exp_path: *experiment_path
      model_subfolder: models/model-id_$SHORT_ID-ep{epoch:03d}.hdf5
  # This callback saves the git version of the given dirs and modules (a commit is required before the run)
  # and stores some other project relevant information (e.g. logging the training process)
  - type: ccmlutils.callbacks.callback_factories.ccmlproject_callback_factory
    params:
      filepath: *experiment_path
      git_modules:
      - *project_package_name
      - ccmlutils

# Optimizer is used in the experiment
optimizer:
  type: tensorflow.keras.optimizers.RMSprop
  params:
    lr: 0.0001
    decay: 0.000001

# With n_classes = 1 the binary crossentropy is used. Otherwise use the same number of classes as in your dataset
n_classes: 1
loss: binary_crossentropy
# loss: categorical_crossentropy
# input_shape for building the model
input_shape: [100, 100, 3]

metric_yaml_file: metrics
test_pipeline_name: testpipeline
train_pipeline_name: trainpipeline
pred_filename: predictions

# Only used for establishing connection between nodes
dummy_arg: ""

### TESTING

# Use either latest or SHORT_ID (e.g. jk3l) for finding the latest experiment
test_exp: latest


